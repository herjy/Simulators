{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing ZTF alerts stored as avro files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import os\n",
    "import io\n",
    "import gzip\n",
    "import tarfile\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from avro.datafile import DataFileReader, DataFileWriter\n",
    "from avro.io import DatumReader, DatumWriter\n",
    "import fastavro\n",
    "\n",
    "from astropy.time import Time\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "import aplpy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract compressed alerts archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "date = [\"20210831\", \"20210910\", \"20210914\", \"20210915\", \"20210916\", \"20210917\", \"20210918\", \"20210919\", \"20210920\",\n",
    "        \"20210921\", \"20210923\", \"20210926\", \"20210927\", \"20210928\", \"20210929\", \"20210930\", \"20211001\", \"20211002\",\n",
    "        \"20211003\", \"20211004\", \"20211007\", \"20211009\", \"20211010\", \"20211011\", \"20211013\", \"20211014\", \"20211015\"]\n",
    "'''\n",
    "date = [\"20211001\", \"20211002\",\n",
    "        \"20211003\", \"20211004\", \"20211007\", \"20211009\", \"20211010\", \"20211011\", \"20211013\", \"20211014\", \"20211015\"]\n",
    "\n",
    "output_dir = []\n",
    "for d in date:\n",
    "    output_dir.append(\"/Volumes/doogesh_HDPro/ZTF/ztf_public_\"+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(root_dir):\n",
    "    for dir_name, subdir_list, file_list in os.walk(root_dir, followlinks=True):\n",
    "        for fname in file_list:\n",
    "            if fname.endswith('.avro'):\n",
    "                yield dir_name+'/'+fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_avro(fname):\n",
    "    with open(fname,'rb') as f:          # modes read and binary     and f is a file\n",
    "        freader = fastavro.reader(f)     # use to read avro file which are coded in binary\n",
    "        # in principle there can be multiple packets per file\n",
    "        for packet in freader:\n",
    "            yield packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dictionaries(root_dir):\n",
    "    for fname in find_files(root_dir):\n",
    "        for packet in open_avro(fname):\n",
    "            yield packet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply some filters/cuts to obtain high purity sample\n",
    "\n",
    "From ZTF Avro documentation: ZTF alert streams contain an nearly entirely unfiltered stream of all 5-sigma (only the most obvious artefacts are rejected). Depending on your science case, you may wish to improve the purity of your sample by filtering the data on the included attributes.\n",
    "\n",
    "Based on tests done at IPAC (F. Masci, priv. comm), the following filter delivers a relatively pure sample:\n",
    "\n",
    "* `rb >= 0.65`\n",
    "* `nbad = 0`\n",
    "* `fwhm <= 5`\n",
    "* `elong <= 1.2`\n",
    "* `abs(magdiff) <= 0.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_alert_pure(packet):\n",
    "    pure = True\n",
    "    # &= to have the intersection between pure and the other 'object'\n",
    "    # use here to select objects satisfying all the previous conditions \n",
    "    pure &= packet['candidate']['rb'] >= 0.65      \n",
    "    pure &= packet['candidate']['nbad'] == 0\n",
    "    pure &= packet['candidate']['fwhm'] <= 5\n",
    "    pure &= packet['candidate']['elong'] <= 1.2\n",
    "    pure &= np.abs(packet['candidate']['magdiff']) <= 0.1\n",
    "    return pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe we do not require this function\n",
    "def generate_programs(output_dir_):\n",
    "\n",
    "    print('{} has {} avro files'.format(output_dir_, len(list(find_files(output_dir_)))))\n",
    "\n",
    "    from collections import defaultdict\n",
    "    programs = defaultdict(int)\n",
    "    for packet in generate_dictionaries(output_dir_):\n",
    "        programs[packet['candidate']['programid']] += 1\n",
    "    print(programs)\n",
    "\n",
    "    return programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe we do not require this function\n",
    "def filter_programs(output_dir_):\n",
    "\n",
    "    programs = defaultdict(int)\n",
    "    for packet in filter(is_alert_pure,generate_dictionaries(output_dir_)):\n",
    "        programs[packet['candidate']['programid']] += 1\n",
    "    print(programs)\n",
    "\n",
    "    return programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For applications using lightcurves it's useful to have the data in a dataframe, but this construction is somewhat slower, so let's apply it after our initial filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(packet):\n",
    "    dfc = pd.DataFrame(packet['candidate'], index=[0])\n",
    "    df_prv = pd.DataFrame(packet['prv_candidates'])\n",
    "    dflc = pd.concat([dfc,df_prv], ignore_index=True)\n",
    "    # we'll attach some metadata--not this may not be preserved after all operations\n",
    "    # https://stackoverflow.com/questions/14688306/adding-meta-information-metadata-to-pandas-dataframe\n",
    "    dflc.objectId = packet['objectId']\n",
    "    dflc.candid = packet['candid']\n",
    "    return dflc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the following cuts to select likely extragalactic transients:\n",
    "* the difference image detection should be positive;\n",
    "* if there is a PS1 source within 1.5\" of the source, it should have a star-galaxy score of < 0.5 (galaxy-like);\n",
    "* there should be at least two detections separated by more than 30 minutes;\n",
    "* there should be no known solar system object within 5\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_transient(dflc):\n",
    "    \n",
    "    candidate = dflc.loc[0]\n",
    "    \n",
    "    is_positive_sub = candidate['isdiffpos'] == 't'\n",
    "    \n",
    "    if (candidate['distpsnr1'] is None) or (candidate['distpsnr1'] > 1.5):\n",
    "        no_pointsource_counterpart = True\n",
    "    else:\n",
    "        if candidate['sgscore1'] < 0.5:\n",
    "            no_pointsource_counterpart = True\n",
    "        else:\n",
    "            no_pointsource_counterpart = False\n",
    "            \n",
    "    where_detected = (dflc['isdiffpos'] == 't') # nondetections will be None\n",
    "    if np.sum(where_detected) >= 2:\n",
    "        detection_times = dflc.loc[where_detected,'jd'].values\n",
    "        dt = np.diff(detection_times)\n",
    "        not_moving = np.max(dt) >= (30*u.minute).to(u.day).value\n",
    "    else:\n",
    "        not_moving = False\n",
    "    \n",
    "    no_ssobject = (candidate['ssdistnr'] is None) or (candidate['ssdistnr'] < 0) or (candidate['ssdistnr'] > 5)\n",
    "    \n",
    "    return is_positive_sub and no_pointsource_counterpart and not_moving and no_ssobject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/ZTF_selection_temp.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wj/f1k4v84n75vfsjmdsxm0kfxh0000gn/T/ipykernel_8469/2717463343.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransient_selection_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/ZTF_selection_temp.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transient_selection_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/ZTF_selection_temp.npz'"
     ]
    }
   ],
   "source": [
    "transient_selection_list = np.load(\"data/ZTF_selection_temp.npz\")['transient_selection_list'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/doogesh_HDPro/ZTF/ztf_public_20211001',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211002',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211003',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211004',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211007',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211009',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211010',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211011',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211013',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211014',\n",
       " '/Volumes/doogesh_HDPro/ZTF/ztf_public_20211015']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transient_selection_list = []\n",
    "\n",
    "pbar = tqdm(total=len(output_dir))\n",
    "\n",
    "for out_dir in output_dir:\n",
    "      # pq il n'y a pas d'argument pour la fonction is_alert_pure ? \n",
    "    for packet in filter(is_alert_pure,generate_dictionaries(out_dir)): \n",
    "        dflc = make_dataframe(packet)\n",
    "        if is_transient(dflc):\n",
    "            #print(packet['objectId'])\n",
    "            if packet['objectId'] not in transient_selection_list:\n",
    "                transient_selection_list.append(packet['objectId'])\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transient_selection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"data/ZTF_selection.npz\", transient_selection_list=transient_selection_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
